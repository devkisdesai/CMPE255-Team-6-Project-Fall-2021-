{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f070fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import pacakages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import pycountry\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "import cufflinks as cf\n",
    "import geopandas as gpd\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Setting global enviorment parameters below for easy viewing\n",
    "pd.set_option('display.max_columns', None) \n",
    "plt.rcParams['figure.figsize'] = [15, 9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a724d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\giga\\anaconda3\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: fiona in c:\\users\\giga\\anaconda3\\lib\\site-packages (from geopandas) (1.8.20)\n",
      "Requirement already satisfied: shapely in c:\\users\\giga\\anaconda3\\lib\\site-packages (from geopandas) (1.8.0)\n",
      "Requirement already satisfied: pandas>=0.23.0 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from geopandas) (1.3.4)\n",
      "Requirement already satisfied: pyproj in c:\\users\\giga\\anaconda3\\lib\\site-packages (from geopandas) (3.3.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from pandas>=0.23.0->geopandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from pandas>=0.23.0->geopandas) (1.21.4+vanilla)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->geopandas) (1.16.0)\n",
      "Requirement already satisfied: gdal~=3.3.0 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (3.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (52.0.0.post20210125)\n",
      "Requirement already satisfied: munch in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (2.5.0)\n",
      "Requirement already satisfied: attrs>=17 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (20.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (2020.12.5)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (7.1.2)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\giga\\anaconda3\\lib\\site-packages (from fiona->geopandas) (0.7.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install geopandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b716e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Datasets/Population Data 1960-2050.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b1de471b2291>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Reading CSV files and removing Unnecessary columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpop_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Datasets/Population Data 1960-2050.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpop_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpop_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Removing unnecessary column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpop_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Datasets/Population Data 1960-2050.csv'"
     ]
    }
   ],
   "source": [
    "# Reading CSV files and removing Unnecessary columns\n",
    "pop_data = pd.read_csv('./Datasets/Population Data 1960-2050.csv', low_memory=False)\n",
    "pop_data = pop_data.replace('..', np.nan)\n",
    "pop_data = pop_data.iloc[: , 1:] # Removing unnecessary column\n",
    "pop_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of columns in the dataset\n",
    "pop_data.dtypes\n",
    "\n",
    "# All the data in the columns are of the type object thus to do any computation on the data we need to convert the data into float.\n",
    "# As most of the data is of float type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0711cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataset of the data where the series name is net Migration as the major focus of this section \n",
    "# is on the net migration section\n",
    "netMigration = pop_data[pop_data.Series_Name == \"Net migration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9a532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "netMigration = netMigration.iloc[:, :70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b88b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "netMigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a782345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data for net migration for each continent \n",
    "\n",
    "\n",
    "Afr = netMigration.loc[netMigration['Continent_Name'] == 'Africa']\n",
    "Asi = netMigration.loc[netMigration['Continent_Name'] == 'Asia']\n",
    "Eur = netMigration.loc[netMigration['Continent_Name'] == 'Europe']\n",
    "Nor = netMigration.loc[netMigration['Continent_Name'] == 'North America']\n",
    "Oce = netMigration.loc[netMigration['Continent_Name'] == 'Oceania']\n",
    "Sou = netMigration.loc[netMigration['Continent_Name'] == 'South America']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35339ac7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Afr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3578b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataCleaning(data):\n",
    "    Countries = pd.DataFrame(data.iloc[:,3])\n",
    "    Migration = pd.DataFrame(data.iloc[:,9::5])\n",
    "    country_migration = Countries.join(Migration.astype('float64')).reset_index(drop = True).dropna( axis=0, \n",
    "                        how='any')\n",
    "    return country_migration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a2c76",
   "metadata": {},
   "source": [
    "- the issue with the net migration data is that the data is recorded in every 5th year ie, in 1962 then in 1967. So I have cleaned the data where I have collected the data forevery 5th year \n",
    "- I have also converted the net migration data columns into float64 dtype so as to calculate sum and average of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5c48a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Afr = DataCleaning(Afr).reset_index(drop = True)\n",
    "Asi = DataCleaning(Asi).reset_index(drop = True)\n",
    "Eur = DataCleaning(Eur).reset_index(drop = True)\n",
    "Nor = DataCleaning(Nor).reset_index(drop = True)\n",
    "Oce = DataCleaning(Oce).reset_index(drop = True)\n",
    "Sou = DataCleaning(Sou).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumByContinentByYear(data):\n",
    "    data = pd.DataFrame(data.sum().to_dict(),index = [data.index.values[-1]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f79f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = ['Africa', 'Asia', 'Europe', 'North America', 'Oceania', 'South America']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ContinentalGrowthAvgByYear = SumByContinentByYear(Afr)\n",
    "ContinentalGrowthAvgByYear = ContinentalGrowthAvgByYear.append(SumByContinentByYear(Asi), ignore_index = True)\n",
    "ContinentalGrowthAvgByYear = ContinentalGrowthAvgByYear.append(SumByContinentByYear(Eur), ignore_index = True)\n",
    "ContinentalGrowthAvgByYear = ContinentalGrowthAvgByYear.append(SumByContinentByYear(Nor), ignore_index = True)\n",
    "ContinentalGrowthAvgByYear = ContinentalGrowthAvgByYear.append(SumByContinentByYear(Oce), ignore_index = True)\n",
    "ContinentalGrowthAvgByYear = ContinentalGrowthAvgByYear.append(SumByContinentByYear(Sou), ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69d8b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ContinentalGrowthAvgByYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d286ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "ContinentalGrowthAvgByYear = ContinentalGrowthAvgByYear.drop(columns=['Country_Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d70a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ContinentalGrowthAvgByYear = ContinentalGrowthAvgByYear.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb45dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ContinentalGrowthAvgByYear.columns = continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a8e3dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ContinentalGrowthAvgByYear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a590119",
   "metadata": {},
   "source": [
    "- In the section above i have calcuated the sum of net migration for each year for each continent and created a dataframe for the same.\n",
    "- Below I have plotted a graph showing a trend in the net migratio over the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec11e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ContinentalGrowthAvgByYear.plot.line(xlabel = 'Year', ylabel = 'Migration', title = 'Migration by Year Per Continent')\n",
    "plt.savefig('./Images/MigrationTrendsByContinent.jpg', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57cd6b",
   "metadata": {},
   "source": [
    "- This graph gives us a proper view of the net migration\n",
    "- From the above graph we can get that from year 1962 to 2022 there has been a trend where there has been a lot of migration towards western countries from asia and africa continent. with a small migration from South America. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc9e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here i am collecting the net migration for all the countries combined so as to train a global model.\n",
    "\n",
    "\n",
    "Continents = pd.DataFrame(netMigration.iloc[:,0])\n",
    "Migration = pd.DataFrame(netMigration.iloc[:,9::5])\n",
    "continent_migration = Continents.join(Migration.astype('float64')).reset_index(drop = True).dropna( axis=0, \n",
    "                        how='any')\n",
    "# Global = continent_migration.reset_index(drop = True)\n",
    "Global = continent_migration.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7782c875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2640561",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Global.iloc[:,1:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9263fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Global.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fcf8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(Global.iloc[:,1:12], Global.iloc[:,-1], test_size=0.4,random_state=109) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef013d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building a linear regression model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25248ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddadc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the mean squared error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804c4745",
   "metadata": {},
   "source": [
    "- Here i tried seperating the data for the net migration and tried to build a regression model over it. \n",
    "- In this model we tried to predict the migration rate for the year 2021 using the data of the previous year.\n",
    "- But in this dataframe we just have 196 datapoints and 12 columns to train on. \n",
    "- The dimensionality of the data is very high and the number of data points is very low so as to obtain a good mean squared error. \n",
    "- The model was trained using a simple linear regression but gave a very bad result.\n",
    "- Initially we assumed that all the columns must be related to each other and there must be a trend in the net migration over the years. But after the model buiding it was clear that our assumption was wrong. As there is not much relation between the net migration in each year column.\n",
    "- Net migration rate depends on more complicated reasons such as development, climate, education, etc and cannot be modeled by using a regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
